 <!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-69X81VG1GW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-69X81VG1GW');
</script>
  <title>Publications | Foundations of Responsible Machine Learning @ UCPH</title>
  <link rel="stylesheet" href="/assets/site.css" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&family=Source+Serif+Pro:wght@600&display=swap" rel="stylesheet">
  <style>
    body { font-family:'Inter',sans-serif; background: #fafafa; }
    h1, h2, h3 { font-family:'Source Serif Pro',serif; }
  </style>
</head>
<body class="bg-gray-50 min-h-screen">
<header class="max-w-4xl mx-auto flex flex-col sm:flex-row sm:items-center sm:justify-between gap-8 mt-16 mb-14 px-4">
  <a href="/" class="text-5xl font-bold tracking-tight text-accent font-serif whitespace-nowrap">
    Cope-FoRML
  </a>
  <nav class="flex space-x-8 text-2xl tracking-wide font-medium">
    <a href="/people/" class="nav-link hover:text-accent">People</a>
    <a href="/publications/" class="nav-link hover:text-accent">Publications</a>
    <a href="/news/" class="nav-link hover:text-accent">News</a>
    <a href="/openings/" class="nav-link hover:text-accent">Openings</a>
  </nav>
</header>

 <main class="max-w-5xl mx-auto px-4">
  




<h1 class="text-3xl font-semibold mb-10">Publications</h1>

<div class="lg:flex lg:gap-12">
  <!-- Filter panel -->
  <aside class="lg:w-1/4 lg:sticky lg:top-24 mb-10 lg:mb-0">
    <input id="search-input" type="text" placeholder="Search title or author" class="w-full border focus:ring-2 ring-accent rounded-lg px-3 py-2 text-sm mb-6" />
    <h2 class="text-sm font-semibold mb-3 text-gray-600">Topics</h2>
    <div class="flex flex-wrap gap-2">
      <button class="chip chip-active" data-topic="all">All</button>
      
        <button class="chip" data-topic="privacy">Privacy</button>
      
        <button class="chip" data-topic="theory">Learning Theory</button>
      
        <button class="chip" data-topic="unlearning">Unlearning</button>
      
        <button class="chip" data-topic="robustness">Robustness</button>
      
        <button class="chip" data-topic="llms">LLMs</button>
      
        <button class="chip" data-topic="data poisoning">Data Poisoning</button>
      
        <button class="chip" data-topic="ml and society">ML and Society</button>
      
    </div>
  </aside>

  <!-- Paper list -->
  <section class="lg:w-3/4 space-y-10" id="paper-container">
    
    
      
        
        <h2 class="sticky-year">2025</h2>
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      
        
      

      
      
      

      <article id="learning-dmitriev-2025" class="paper-card" data-topics="theory" data-tags="robustness,online learning">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Learning in an Echo Chamber: Online Learning with Replay Adversary</h3>
          <p class="authors">Daniil Dmitriev, Harald Eskelund Franck, Carolin Heinzler, Amartya Sanyal</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-accent">
    Symposium on Discrete Algorithms (SODA)
  </span>
  <span class="text-xs text-gray-500">
    Symposium on Discrete Algorithms (SODA) (2025)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2509.25135" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="learning-dmitriev-2025"
    data-title="Learning in an Echo Chamber: Online Learning with Replay Adversary"
    data-authors="Dmitriev, Daniil and Franck, Harald Eskelund and Heinzler, Carolin and Sanyal, Amartya"
    data-year="2025"
    data-venue="Symposium on Discrete Algorithms (SODA) (Symposium on Discrete Algorithms (SODA))"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="robustness">robustness</button><button class="tag" data-tag="online learning">online learning</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
      

      
      
      
        
        
          
        
      

      <article id="fairness-bendov-2025" class="paper-card" data-topics="ml and society" data-tags="collective action,ml and society">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Fairness for the People, by the People: Minority Collective Action</h3>
          <p class="authors">Omri Ben‑Dov, Samira Samadi, Amartya Sanyal, Alexandru Ţifrea</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-gray-500">
    Preprint
  </span>
  <span class="text-xs text-gray-500">
    arXiv Preprint (2025)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2508.15374" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="fairness-bendov-2025"
    data-title="Fairness for the People, by the People: Minority Collective Action"
    data-authors="Ben‑Dov, Omri and Samadi, Samira and Sanyal, Amartya and Ţifrea, Alexandru"
    data-year="2025"
    data-venue="arXiv Preprint (Preprint)"
    data-field="journal"
    data-type="article"
    data-arxiv="arXiv:2508.15374"
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="collective action">collective action</button><button class="tag" data-tag="ml and society">ml and society</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="an-dngler-2025" class="paper-card" data-topics="privacy,theory" data-tags="privacy">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">An Iterative Algorithm for Differentially Private k-PCA with Adaptive Noise</h3>
          <p class="authors">Johanna Düngler, Amartya Sanyal</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-green-500">
    NeurIPS
  </span>
  <span class="text-xs text-gray-500">
    Conference on Neural Information Processing Systems (2025)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2508.10879" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="an-dngler-2025"
    data-title="An Iterative Algorithm for Differentially Private k-PCA with Adaptive Noise"
    data-authors="Düngler, Johanna and Sanyal, Amartya"
    data-year="2025"
    data-venue="Conference on Neural Information Processing Systems (NeurIPS)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="privacy">privacy</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="provable-wei-2025" class="paper-card" data-topics="unlearning,theory" data-tags="unlearning">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Provable Unlearning in Topic Modeling and Downstream Tasks</h3>
          <p class="authors">Stanley Wei, Sadhika Malladi, Sanjeev Arora, Amartya Sanyal</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-emerald-500">
    ICLR
  </span>
  <span class="text-xs text-gray-500">
    International Conference on Learning Representations (2025)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2411.12600" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="provable-wei-2025"
    data-title="Provable Unlearning in Topic Modeling and Downstream Tasks"
    data-authors="Wei, Stanley and Malladi, Sadhika and Arora, Sanjeev and Sanyal, Amartya"
    data-year="2025"
    data-venue="International Conference on Learning Representations (ICLR)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="unlearning">unlearning</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="differentially-goel-2025" class="paper-card" data-topics="privacy,llms" data-tags="ai safety,differential privacy,llms">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Differentially Private Steering for Large Language Model Alignment</h3>
          <p class="authors">Anmol Goel, Yaxi Hu, Iryna Gurevych, Amartya Sanyal</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-emerald-500">
    ICLR
  </span>
  <span class="text-xs text-gray-500">
    International Conference on Learning Representations (2025)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2501.18532" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="differentially-goel-2025"
    data-title="Differentially Private Steering for Large Language Model Alignment"
    data-authors="Goel, Anmol and Hu, Yaxi and Gurevych, Iryna and Sanyal, Amartya"
    data-year="2025"
    data-venue="International Conference on Learning Representations (ICLR)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="ai safety">ai safety</button><button class="tag" data-tag="differential privacy">differential privacy</button><button class="tag" data-tag="llms">llms</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="protecting-neel-2025" class="paper-card" data-topics="robustness,data poisoning" data-tags="data poisoning,ai safety,robustness">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Protecting Against Simultaneous Data Poisoning Attacks</h3>
          <p class="authors">Alex Neel, Shoaib Ahmed Siddiqui, Amartya Sanyal, David Krueger</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-emerald-500">
    ICLR
  </span>
  <span class="text-xs text-gray-500">
    International Conference on Learning Representations (2025)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2408.13221" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="protecting-neel-2025"
    data-title="Protecting Against Simultaneous Data Poisoning Attacks"
    data-authors="Neel, Alex and Siddiqui, Shoaib Ahmed and Sanyal, Amartya and Krueger, David"
    data-year="2025"
    data-venue="International Conference on Learning Representations (ICLR)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="data poisoning">data poisoning</button><button class="tag" data-tag="ai safety">ai safety</button><button class="tag" data-tag="robustness">robustness</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="accuracy-sanyal-2025" class="paper-card" data-topics="robustness" data-tags="robustness,label noise,ai safety">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Accuracy on the Wrong Line: On the Pitfalls of Noisy Data for Out-of-Distribution Generalisation</h3>
          <p class="authors">Amartya Sanyal, Yaxi Hu, Yaodong Yu, Yian Ma, Yixin Wang, Bernhard Schölkopf</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-indigo-500">
    AISTATS
  </span>
  <span class="text-xs text-gray-500">
    Artificial Intelligence and Statistics (2025)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2406.19049" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="accuracy-sanyal-2025"
    data-title="Accuracy on the Wrong Line: On the Pitfalls of Noisy Data for Out-of-Distribution Generalisation"
    data-authors="Sanyal, Amartya and Hu, Yaxi and Yu, Yaodong and Ma, Yian and Wang, Yixin and Schölkopf, Bernhard"
    data-year="2025"
    data-venue="Artificial Intelligence and Statistics (AISTATS)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="robustness">robustness</button><button class="tag" data-tag="label noise">label noise</button><button class="tag" data-tag="ai safety">ai safety</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
          
          
          
          
          
            
            
          
        
      
      

      
      
      
        
        
          
        
      

      <article id="online-hu-2025" class="paper-card" data-topics="unlearning,theory" data-tags="online learning,unlearning,privacy">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Online Learning and Unlearning</h3>
          <p class="authors">Yaxi Hu, Bernhard Schölkopf, Amartya Sanyal</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-gray-500">
    Preprint
  </span>
  <span class="text-xs text-gray-500">
    Preprint (2025)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2505.08557" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="online-hu-2025"
    data-title="Online Learning and Unlearning"
    data-authors="Hu, Yaxi and Schölkopf, Bernhard and Sanyal, Amartya"
    data-year="2025"
    data-venue="Preprint (Preprint)"
    data-field="journal"
    data-type="article"
    data-arxiv="arXiv:2505.08557"
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="online learning">online learning</button><button class="tag" data-tag="unlearning">unlearning</button><button class="tag" data-tag="privacy">privacy</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
          
          
          
          
          
            
            
          
        
      
      

      
      
      
        
        
          
        
      

      <article id="open-barez-2025" class="paper-card" data-topics="unlearning,llms" data-tags="unlearning,ai safety">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Open problems in machine unlearning for ai safety</h3>
          <p class="authors">Fazl Barez, Tingchen Fu, Ameya Prabhu, Stephen Casper, Amartya Sanyal, Adel Bibi, Aidan O&#39;Gara, Robert Kirk, Ben Bucknall, Tim Fist, others</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-gray-500">
    Preprint
  </span>
  <span class="text-xs text-gray-500">
    Preprint (2025)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2501.04952" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="open-barez-2025"
    data-title="Open problems in machine unlearning for ai safety"
    data-authors="Barez, Fazl and Fu, Tingchen and Prabhu, Ameya and Casper, Stephen and Sanyal, Amartya and Bibi, Adel and O&#39;Gara, Aidan and Kirk, Robert and Bucknall, Ben and Fist, Tim and others"
    data-year="2025"
    data-venue="Preprint (Preprint)"
    data-field="journal"
    data-type="article"
    data-arxiv="arXiv:2501.04952"
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="unlearning">unlearning</button><button class="tag" data-tag="ai safety">ai safety</button>
          </div>
        </div>
      </article>
    
      
        
        <h2 class="sticky-year">2024</h2>
      

      
      
      
      
      
      
      
      
      
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="robust-dmitriev-2024" class="paper-card" data-topics="robustness,theory" data-tags="robustness">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Robust Mixture Learning when Outliers Overwhelm Small Groups</h3>
          <p class="authors">Daniil Dmitriev, Rares‑Darius Buhai, Stefan Tiegel, Alexander Wolters, Gleb Novikov, Amartya Sanyal, David Steurer, Fanny Yang</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-green-500">
    NeurIPS
  </span>
  <span class="text-xs text-gray-500">
    Conference on Neural Information Processing Systems (2024)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2407.15792" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="robust-dmitriev-2024"
    data-title="Robust Mixture Learning when Outliers Overwhelm Small Groups"
    data-authors="Dmitriev, Daniil and Buhai, Rares‑Darius and Tiegel, Stefan and Wolters, Alexander and Novikov, Gleb and Sanyal, Amartya and Steurer, David and Yang, Fanny"
    data-year="2024"
    data-venue="Conference on Neural Information Processing Systems (NeurIPS)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="robustness">robustness</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="what-jain-2024" class="paper-card" data-topics="llms" data-tags="llm,ai safety">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">What Makes and Breaks Safety Fine-tuning? A Mechanistic Study</h3>
          <p class="authors">Samyak Jain, Ekdeep Singh Lubana, Kemal Oksuz, Tom Joy, Philip Torr, Amartya Sanyal, Puneet K. Dokania</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-green-500">
    NeurIPS
  </span>
  <span class="text-xs text-gray-500">
    Conference on Neural Information Processing Systems (2024)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2407.10264" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="what-jain-2024"
    data-title="What Makes and Breaks Safety Fine-tuning? A Mechanistic Study"
    data-authors="Jain, Samyak and Lubana, Ekdeep Singh and Oksuz, Kemal and Joy, Tom and Torr, Philip and Sanyal, Amartya and Dokania, Puneet K."
    data-year="2024"
    data-venue="Conference on Neural Information Processing Systems (NeurIPS)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="llm">llm</button><button class="tag" data-tag="ai safety">ai safety</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="provable-hu-2024" class="paper-card" data-topics="privacy,theory" data-tags="differential privacy">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Provable Privacy with Non-Private Pre-Processing</h3>
          <p class="authors">Yaxi Hu, Amartya Sanyal, Bernhard Schölkopf</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-blue-500">
    ICML
  </span>
  <span class="text-xs text-gray-500">
    International Conference on Machine Learning (2024)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2403.13041" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="provable-hu-2024"
    data-title="Provable Privacy with Non-Private Pre-Processing"
    data-authors="Hu, Yaxi and Sanyal, Amartya and Schölkopf, Bernhard"
    data-year="2024"
    data-venue="International Conference on Machine Learning (ICML)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="differential privacy">differential privacy</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="the-bendov-2024" class="paper-card" data-topics="ml and society" data-tags="collective action,ml and society">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">The Role of Learning Algorithms in Collective Action</h3>
          <p class="authors">Omri Ben‑Dov, Jake Fawkes, Samira Samadi, Amartya Sanyal</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-blue-500">
    ICML
  </span>
  <span class="text-xs text-gray-500">
    International Conference on Machine Learning (2024)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2405.06582" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="the-bendov-2024"
    data-title="The Role of Learning Algorithms in Collective Action"
    data-authors="Ben‑Dov, Omri and Fawkes, Jake and Samadi, Samira and Sanyal, Amartya"
    data-year="2024"
    data-venue="International Conference on Machine Learning (ICML)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="collective action">collective action</button><button class="tag" data-tag="ml and society">ml and society</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
        
      
      

      
      
      

      <article id="on-dmitriev-2024" class="paper-card" data-topics="privacy,theory" data-tags="online learning,lower bounds,differential privacy">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">On the Growth of Mistakes in Differentially Private Online Learning: A Lower Bound Perspective</h3>
          <p class="authors">Daniil Dmitriev, Kristóf Szabó, Amartya Sanyal</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-cyan-500">
    COLT
  </span>
  <span class="text-xs text-gray-500">
    Conference on Learning Theory (2024)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2402.16778" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="on-dmitriev-2024"
    data-title="On the Growth of Mistakes in Differentially Private Online Learning: A Lower Bound Perspective"
    data-authors="Dmitriev, Daniil and Szabó, Kristóf and Sanyal, Amartya"
    data-year="2024"
    data-venue="Conference on Learning Theory (COLT)"
    data-field="booktitle"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="online learning">online learning</button><button class="tag" data-tag="lower bounds">lower bounds</button><button class="tag" data-tag="differential privacy">differential privacy</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
      
        
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
        
      
      

      
      
      

      <article id="corrective-goel-2024" class="paper-card" data-topics="unlearning,data poisoning" data-tags="unlearning,robustness">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Corrective Machine Unlearning</h3>
          <p class="authors">Shashwat Goel, Ameya Prabhu, Philip Torr, Ponnurangam Kumaraguru, Amartya Sanyal</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-purple-500">
    TMLR
  </span>
  <span class="text-xs text-gray-500">
    Transactions on Machine Learning Research (2024)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2402.14015" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="corrective-goel-2024"
    data-title="Corrective Machine Unlearning"
    data-authors="Goel, Shashwat and Prabhu, Ameya and Torr, Philip and Kumaraguru, Ponnurangam and Sanyal, Amartya"
    data-year="2024"
    data-venue="Transactions on Machine Learning Research (TMLR)"
    data-field="journal"
    data-type="inproceedings"
    data-arxiv=""
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="unlearning">unlearning</button><button class="tag" data-tag="robustness">robustness</button>
          </div>
        </div>
      </article>
    
      

      
      
      
      
      
      
      
      
      
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          
          
          
          
          
            
            
          
        
      
        
      
      

      
      
      
        
        
          
        
      

      <article id="deltainfluence-li-2024" class="paper-card" data-topics="unlearning,data poisoning" data-tags="unlearning,robustness,ai safety,data poisoning">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Delta-influence: Unlearning poisons via influence functions</h3>
          <p class="authors">Wenjie Li, Jiawei Li, Christian Schroeder de Witt, Ameya Prabhu, Amartya Sanyal</p>
<div class="flex items-center gap-4 mb-1">
  <span class="inline-block px-2 py-0.5 rounded text-xs font-bold text-white bg-gray-500">
    Preprint
  </span>
  <span class="text-xs text-gray-500">
    arXiv Preprint (2024)
  </span>
</div>

<div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2411.13731" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
            <button class="action-btn bibtex-btn"
              data-slug="deltainfluence-li-2024"
    data-title="Delta-influence: Unlearning poisons via influence functions"
    data-authors="Li, Wenjie and Li, Jiawei and de Witt, Christian Schroeder and Prabhu, Ameya and Sanyal, Amartya"
    data-year="2024"
    data-venue="arXiv Preprint (Preprint)"
    data-field="journal"
    data-type="article"
    data-arxiv="arXiv:2411.13731"
            >BibTeX</button>
          </div>
          
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="unlearning">unlearning</button><button class="tag" data-tag="robustness">robustness</button><button class="tag" data-tag="ai safety">ai safety</button><button class="tag" data-tag="data poisoning">data poisoning</button>
          </div>
        </div>
      </article>
    
  </section>
</div>

<script>
  // Pre-fill search with ?author=
  function getQueryParam(name) {
    return new URLSearchParams(window.location.search).get(name);
  }
  document.addEventListener("DOMContentLoaded", function() {
    const author = getQueryParam("author");
    if (author) {
      const search = document.getElementById("search-input");
      if (search) {
        search.value = author;
        var evt = new Event('input', { bubbles: true });
        search.dispatchEvent(evt);
      }
    }
    // BibTeX copy handler
    document.querySelectorAll('.bibtex-btn').forEach(btn => {
      btn.addEventListener('click', function() {
        const slug = btn.dataset.slug;
        const title = btn.dataset.title;
        const authors = btn.dataset.authors;
        const year = btn.dataset.year;
        const venue = btn.dataset.venue;
        const field = btn.dataset.field || 'booktitle';
        const type = btn.dataset.type || 'inproceedings';
        const arxiv = btn.dataset.arxiv;
        // Remove curly braces in venue/title/authors to avoid nested braces
        function clean(s) { return s.replace(/[{}]/g,''); }
        let bibtex = '';
        if(type === 'article' && arxiv) {
          bibtex = `@article{${slug},
  title = {${clean(title)}},
  author = {${clean(authors)}},
  year = {${year}},
  journal = {${clean(arxiv)}}
}`;
        } else {
          bibtex = `@${type}{${slug},
  title = {${clean(title)}},
  author = {${clean(authors)}},
  year = {${year}},
  ${field} = {${clean(venue)}}
}`;
        }
        navigator.clipboard.writeText(bibtex);
        btn.textContent = 'Copied!';
        setTimeout(() => { btn.textContent = 'BibTeX'; }, 1200);
      });
    });
  });

  // Filtering
  const chips=document.querySelectorAll('.chip');
  const cards=document.querySelectorAll('.paper-card');
  const searchInput=document.getElementById('search-input');
  let topic='all', q='';
  function apply(){
    const query = q.toLowerCase();
    cards.forEach(c=>{
      const topics = c.dataset.topics.toLowerCase().split(',').map(s=>s.trim());
      const show = (topic==='all' || topics.includes(topic)) &&
                   c.textContent.toLowerCase().includes(query);
      c.classList.toggle('hidden', !show);
      c.classList.toggle('opacity-0', !show);
      c.classList.toggle('scale-95', !show);
    });
  }
  chips.forEach(btn=>btn.onclick=()=>{chips.forEach(b=>b.classList.remove('chip-active'));btn.classList.add('chip-active');topic=btn.dataset.topic;apply();});
  searchInput.oninput=()=>{q=searchInput.value;apply();};
  document.getElementById('paper-container').addEventListener('click',e=>{if(e.target.matches('.tag')){searchInput.value=e.target.dataset.tag;q=e.target.dataset.tag;apply();}});
</script>

</main>

<footer class="mt-24 text-base text-gray-400 border-t pt-16 pb-20 max-w-4xl mx-auto px-4">
  © 2025 Amartya Sanyal  · Cope-FoRML · University of Copenhagen
</footer>
</body>
</html>
