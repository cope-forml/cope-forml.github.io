 <!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Publications | Foundations of Responsible Machine Learning @ UCPH</title>
  <link rel="stylesheet" href="/assets/site.css" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&family=Source+Serif+Pro:wght@600&display=swap" rel="stylesheet">
  <style>
    body { font-family:'Inter',sans-serif; background: #fafafa; }
    h1, h2, h3 { font-family:'Source Serif Pro',serif; }
  </style>
</head>
<body class="bg-gray-50 min-h-screen">
<header class="max-w-4xl mx-auto flex flex-col sm:flex-row sm:items-center sm:justify-between gap-8 mt-16 mb-14 px-4">
  <a href="/" class="text-5xl font-bold tracking-tight text-accent font-serif whitespace-nowrap">
    Cope-FoRML
  </a>
  <nav class="flex space-x-8 text-2xl tracking-wide font-medium">
    <a href="/people/" class="nav-link hover:text-accent">People</a>
    <a href="/publications/" class="nav-link hover:text-accent">Publications</a>
    <a href="/news/" class="nav-link hover:text-accent">News</a>
    <a href="/openings/" class="nav-link hover:text-accent">Openings</a>
  </nav>
</header>

 <main class="max-w-5xl mx-auto px-4">
  


<h1 class="text-3xl font-semibold mb-10">Publications</h1>

<div class="lg:flex lg:gap-12">
  <!-- Filter panel -->
  <aside class="lg:w-1/4 lg:sticky lg:top-24 mb-10 lg:mb-0">
    <input id="search-input" type="text" placeholder="Search title or author" class="w-full border focus:ring-2 ring-accent rounded-lg px-3 py-2 text-sm mb-6" />
    <h2 class="text-sm font-semibold mb-3 text-gray-600">Topics</h2>
    <div class="flex flex-wrap gap-2">
      <button class="chip chip-active" data-topic="all">All</button>
      
        <button class="chip" data-topic="privacy">Privacy</button>
      
        <button class="chip" data-topic="theory">Learning Theory</button>
      
        <button class="chip" data-topic="unlearning">Unlearning</button>
      
        <button class="chip" data-topic="robustness">Robustness</button>
      
        <button class="chip" data-topic="llms">LLMs</button>
      
        <button class="chip" data-topic="data poisoning">Data Poisoning</button>
      
        <button class="chip" data-topic="ml and society">ML and Society</button>
      
    </div>
  </aside>

  <!-- Paper list -->
  <section class="lg:w-3/4 space-y-10" id="paper-container">
    
    
      
        
        <h2 class="sticky-year">2025</h2>
      
      <article id="provable-unlearning-in-topic-modeling-and-downstream-tasks" class="paper-card" data-topics="unlearning,theory" data-tags="unlearning">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Provable Unlearning in Topic Modeling and Downstream Tasks</h3>
          <p class="authors">Stanley Wei, Sadhika Malladi, Sanjeev Arora, Amartya Sanyal</p>

          <p class="venue">Proceedings of the Thirteenth International Conference on Learning Representations (ICLR) (2025)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2411.12600" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="unlearning">unlearning</button>
          </div>
        </div>
      </article>
    
      
      <article id="differentially-private-steering-for-large-language-model-alignment" class="paper-card" data-topics="privacy,llms" data-tags="ai safety,differential privacy,llms">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Differentially Private Steering for Large Language Model Alignment</h3>
          <p class="authors">Anmol Goel, Yaxi Hu, Iryna Gurevych, Amartya Sanyal</p>

          <p class="venue">Proceedings of the Thirteenth International Conference on Learning Representations (ICLR) (2025)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2501.18532" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="ai safety">ai safety</button><button class="tag" data-tag="differential privacy">differential privacy</button><button class="tag" data-tag="llms">llms</button>
          </div>
        </div>
      </article>
    
      
      <article id="protecting-against-simultaneous-data-poisoning-attacks" class="paper-card" data-topics="robustness,data poisoning" data-tags="data poisoning,ai safety,robustness">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Protecting Against Simultaneous Data Poisoning Attacks</h3>
          <p class="authors">Alex Neel, Shoaib Ahmed Siddiqui, Amartya Sanyal, David Krueger</p>

          <p class="venue">Proceedings of the Thirteenth International Conference on Learning Representations (ICLR) (2025)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2408.13221" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="data poisoning">data poisoning</button><button class="tag" data-tag="ai safety">ai safety</button><button class="tag" data-tag="robustness">robustness</button>
          </div>
        </div>
      </article>
    
      
      <article id="accuracy-on-the-wrong-line-on-the-pitfalls-of-noisy-data-for-out-of-distribution-generalisation" class="paper-card" data-topics="robustness" data-tags="robustness,label noise,ai safety">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Accuracy on the Wrong Line: On the Pitfalls of Noisy Data for Out-of-Distribution Generalisation</h3>
          <p class="authors">Amartya Sanyal, Yaxi Hu, Yaodong Yu, Yian Ma, Yixin Wang, Bernhard Schölkopf</p>

          <p class="venue">Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS) (2025)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2406.19049" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="robustness">robustness</button><button class="tag" data-tag="label noise">label noise</button><button class="tag" data-tag="ai safety">ai safety</button>
          </div>
        </div>
      </article>
    
      
      <article id="online-learning-and-unlearning" class="paper-card" data-topics="unlearning,theory" data-tags="online learning,unlearning,privacy">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Online Learning and Unlearning</h3>
          <p class="authors">Yaxi Hu, Bernhard Schölkopf, Amartya Sanyal</p>

          <p class="venue">arXiv preprint arXiv:2505.08557 (2025)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2505.08557" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="online learning">online learning</button><button class="tag" data-tag="unlearning">unlearning</button><button class="tag" data-tag="privacy">privacy</button>
          </div>
        </div>
      </article>
    
      
      <article id="open-problems-in-machine-unlearning-for-ai-safety" class="paper-card" data-topics="unlearning" data-tags="unlearning,ai safety">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Open problems in machine unlearning for ai safety</h3>
          <p class="authors">Fazl Barez, Tingchen Fu, Ameya Prabhu, Stephen Casper, Amartya Sanyal, Adel Bibi, Aidan O&#39;Gara, Robert Kirk, Ben Bucknall, Tim Fist, others</p>

          <p class="venue">arXiv preprint arXiv:2501.04952 (2025)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2501.04952" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="unlearning">unlearning</button><button class="tag" data-tag="ai safety">ai safety</button>
          </div>
        </div>
      </article>
    
      
        
        <h2 class="sticky-year">2024</h2>
      
      <article id="robust-mixture-learning-when-outliers-overwhelm-small-groups" class="paper-card" data-topics="robustness,theory" data-tags="robustness">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Robust Mixture Learning when Outliers Overwhelm Small Groups</h3>
          <p class="authors">Daniil Dmitriev, Rares‑Darius Buhai, Stefan Tiegel, Alexander Wolters, Gleb Novikov, Amartya Sanyal, David Steurer, Fanny Yang</p>

          <p class="venue">Advances in Neural Information Processing Systems (NeurIPS) (2024)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2407.15792" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="robustness">robustness</button>
          </div>
        </div>
      </article>
    
      
      <article id="what-makes-and-breaks-safety-fine-tuning-a-mechanistic-study" class="paper-card" data-topics="llms" data-tags="llm,ai safety">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">What Makes and Breaks Safety Fine-tuning? A Mechanistic Study</h3>
          <p class="authors">Samyak Jain, Ekdeep Singh Lubana, Kemal Oksuz, Tom Joy, Philip Torr, Amartya Sanyal, Puneet K. Dokania</p>

          <p class="venue">Advances in Neural Information Processing Systems (NeurIPS) (2024)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2407.10264" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="llm">llm</button><button class="tag" data-tag="ai safety">ai safety</button>
          </div>
        </div>
      </article>
    
      
      <article id="provable-privacy-with-non-private-pre-processing" class="paper-card" data-topics="privacy,theory" data-tags="differential privacy">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Provable Privacy with Non-Private Pre-Processing</h3>
          <p class="authors">Yaxi Hu, Amartya Sanyal, Bernhard Schölkopf</p>

          <p class="venue">Proceedings of the 41st International Conference on Machine Learning (ICML) / Theory and Practice of Differential Privacy (TPDP) (2024)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2403.13041" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="differential privacy">differential privacy</button>
          </div>
        </div>
      </article>
    
      
      <article id="the-role-of-learning-algorithms-in-collective-action" class="paper-card" data-topics="ml and society" data-tags="collective action,ml and society">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">The Role of Learning Algorithms in Collective Action</h3>
          <p class="authors">Omri Ben‑Dov, Jake Fawkes, Samira Samadi, Amartya Sanyal</p>

          <p class="venue">Proceedings of the 41st International Conference on Machine Learning (ICML) (2024)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2405.06582" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="collective action">collective action</button><button class="tag" data-tag="ml and society">ml and society</button>
          </div>
        </div>
      </article>
    
      
      <article id="on-the-growth-of-mistakes-in-differentially-private-online-learning-a-lower-bound-perspective" class="paper-card" data-topics="privacy,theory" data-tags="online learning,lower bounds,differential privacy">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">On the Growth of Mistakes in Differentially Private Online Learning: A Lower Bound Perspective</h3>
          <p class="authors">Daniil Dmitriev, Kristóf Szabó, Amartya Sanyal</p>

          <p class="venue">Conference on Learning Theory (COLT) / Theory and Practice of Differential Privacy (TPDP) (2024)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2402.16778" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="online learning">online learning</button><button class="tag" data-tag="lower bounds">lower bounds</button><button class="tag" data-tag="differential privacy">differential privacy</button>
          </div>
        </div>
      </article>
    
      
      <article id="corrective-machine-unlearning" class="paper-card" data-topics="unlearning,data poisoning" data-tags="unlearning,robustness">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Corrective Machine Unlearning</h3>
          <p class="authors">Shashwat Goel, Ameya Prabhu, Philip Torr, Ponnurangam Kumaraguru, Amartya Sanyal</p>

          <p class="venue">Transactions on Machine Learning Research (TMLR) (2024)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2402.14015" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="unlearning">unlearning</button><button class="tag" data-tag="robustness">robustness</button>
          </div>
        </div>
      </article>
    
      
      <article id="delta-influence-unlearning-poisons-via-influence-functions" class="paper-card" data-topics="unlearning" data-tags="unlearning,robustness,ai safety,data poisoning">
        <span class="accent-bar"></span>
        <div class="p-4 pl-5">
          <h3 class="title">Delta-influence: Unlearning poisons via influence functions</h3>
          <p class="authors">Wenjie Li, Jiawei Li, Christian Schroeder de Witt, Ameya Prabhu, Amartya Sanyal</p>

          <p class="venue">arXiv:2411.13731 (2024)</p>
          <div class="actions flex flex-wrap gap-2 text-xs mb-3">
            
            
            
            
              
                <a href="https://arxiv.org/abs/2411.13731" aria-label="arXiv" class="action-btn">arXiv</a>
              
            
          </div>
          <div class="tags flex flex-wrap gap-1">
            <button class="tag" data-tag="unlearning">unlearning</button><button class="tag" data-tag="robustness">robustness</button><button class="tag" data-tag="ai safety">ai safety</button><button class="tag" data-tag="data poisoning">data poisoning</button>
          </div>
        </div>
      </article>
    
  </section>
</div>

<script>
  // Pre-fill search with ?author=
  function getQueryParam(name) {
    return new URLSearchParams(window.location.search).get(name);
  }
  document.addEventListener("DOMContentLoaded", function() {
    const author = getQueryParam("author");
    if (author) {
      const search = document.getElementById("search-input");
      if (search) {
        search.value = author;
        var evt = new Event('input', { bubbles: true });
        search.dispatchEvent(evt);
      }
    }
  });

  // Filtering
  const chips=document.querySelectorAll('.chip');
  const cards=document.querySelectorAll('.paper-card');
  const searchInput=document.getElementById('search-input');
  let topic='all', q='';
  function apply(){
    const query = q.toLowerCase();
    cards.forEach(c=>{
      const topics = c.dataset.topics.toLowerCase().split(',').map(s=>s.trim());
      const show = (topic==='all' || topics.includes(topic)) &&
                   c.textContent.toLowerCase().includes(query);
      c.classList.toggle('hidden', !show);
      c.classList.toggle('opacity-0', !show);
      c.classList.toggle('scale-95', !show);
    });
  }
  chips.forEach(btn=>btn.onclick=()=>{chips.forEach(b=>b.classList.remove('chip-active'));btn.classList.add('chip-active');topic=btn.dataset.topic;apply();});
  searchInput.oninput=()=>{q=searchInput.value;apply();};
  document.getElementById('paper-container').addEventListener('click',e=>{if(e.target.matches('.tag')){searchInput.value=e.target.dataset.tag;q=e.target.dataset.tag;apply();}});
</script>

</main>

<footer class="mt-24 text-base text-gray-400 border-t pt-16 pb-20 max-w-4xl mx-auto px-4">
  © 2025 Amartya Sanyal  · Cope-FoRML · University of Copenhagen
</footer>
</body>
</html>
